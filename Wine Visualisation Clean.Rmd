---
title: "How Many Wines are there Really?  A Visualisation"
author: "Martin Wood"
date: "9 March 2019"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(kohonen)       # Functions for Self-Organising Maps
library(visdat)        # For visualisations useful for initial exploration (eg; missingness)
library(ggplot2)
library(reshape2)
library(plotly)

setwd("/mnt/store/Projects/clustering_wine_descriptions")

# Define a color scheme to use
vis_scheme <- "YlOrRd"

```

## Data Preparation

Load the data and drop some columns related to the topics demonstrated to be irrelevant to wine flavour.

```{r loading}
# Load the original metadata on wines
wine_df <- read.csv("./data/wine_reviews_with_14_topic_distributions_clean.csv")

# Drop the topics which we know to be "duds" from exploration in Python ()
wine_df <- subset(wine_df, select = -c(X0, X2, X4, X7, X12, index))

wine_df <- drop_na(wine_df)

# Load the topic word distributions
word_dist_df <- read.csv("./data/topic_14_word_dist_5_clean.csv")

# Drop the topics we're excluding
word_dist_df <- word_dist_df[-c(1, 3, 5, 8, 13),]

# Do I need to delete duplicates here?  Include just incase something goes funny with Python model
wine_df <- wine_df[!duplicated(wine_df$description),]
dim(wine_df)
```

Assign each wine to the topic for which it has the greatest probability.  This step is poorly implemented and may take a moment.

```{r assign_topic}
# Quick utility function; returns index of max-valued element of vector/matrix
max_index <- function(x) {
  which(x==max(x))
}

# Quickly iterate over and assign each wine to the topic with highest probability for that document
# The conversions serve to strip uneccessary indexing information created either by the "which" function
# or by the "apply" function.
wine_df['topics'] <- as.character( apply(wine_df[,18:26], 1, max_index)  )

# Filter entries that have been assigned to multiple topics - valid but unhelpful
wine_df <- wine_df[lapply(wine_df$topics, nchar) < 3, ]

# Record for each wine its topic probability for that highest probability wine, for my own convenience later
wine_df['topic_certainty'] <- apply(wine_df[,18:26], 1, max)
```


## Data Exploration

### Missing/invalid data still present

There's a small number (71) of wines without assigned countries.  Since this is significantly fewer wines than make up the membership of even the smallest cluster we shall simply ignore them.  They shouldn't impact any of the planned visualisations and I'd like to retain their topic information for SOM generation.

Below the descriptions are ordered by length of description - there's a small number with no real description, only a note on where they've been sourced from or a note to the effect of "no available description".  Since they're hard to filter out (no unique identifier) and small in number they're left in.  They'll have little to no effect on the analysis.

```{r}
# Missing Descriptions
head(wine_df[order(wine_df$desc_len),c("title", "description")], n=30)
```

### Looking at frequencies of countries

The US rather dominates with ~ 50,000 records!  We're going to assume the wine magazine's reporters were really thorough, and their ratios are reflective of the world of wine at large.  There are also many countries with very few wines.  To make reasonable plots I may limit plots by country to countries with > 1000 wines.

```{r explore_countries}
# Calculate some stats on the number of wines from different countries
priors <- data.frame(table(wine_df['country']))
priors['frac'] <- priors['Freq'] / sum(priors['Freq'])
priors <- priors[order(-priors$frac),]

colnames(priors) <- c("country", "freq", "frac")
priors
```


### Looking at topics versus countries

It's visually apparent that different topics have different distributions over the countries of origin of their wines.  This lends some credence to the methodology, you'd expect them to be different but with a lot of overlap and noise due to the overall dependence on local climate and soil types.

We can also determine the country that most closely relates to a given topic by looking at the most frequent country of origin (weighted by prior odds - some countries just produce lots of wines and if you don't do this the US dominates!).

```{r explore_topics}
# What's the relative membership of topics?
summary(wine_df['topics'])
summary(wine_df['country'])
ggplot(data=wine_df, aes(x=topics, fill=country)) + geom_bar()
```

```{r dominant_country}
# For each cluster, what's the dominant country of origin?
wines_count <- wine_df %>% count(country, topics)

wines_count <- wines_count %>% merge(priors, by="country")
wines_count['weighted_n'] <- wines_count['n'] / wines_count['frac']

# drop any country with < 1000 wines to its name because it messes with the stats!
wines_count <- wines_count[wines_count['freq'] >=1000, ]
wines_count %>% group_by(topics) %>% top_n(1, weighted_n) -> topic_dominant_country

topic_dominant_country
```

### Looking at the wines

What's the most representative wine for a given topic?  Simply find the wine with the highest probability of belonging to that topic.  These are the archetypes, those most similar to all other wines in a group and therefore the wines to try if you want to sample something truly representative!

```{r dominant_wine}
# What's the most representative single wine for each topic, that for which the topic probability is highest?
wine_df %>% group_by(topics) %>% top_n(1, topic_certainty) -> wine_archetypes
wine_archetypes[,c("topics", "country", "title")]
```


## Plot the topic space (SOM's)

### Creating the SOM model

To do this we first iteratively fit a 30 * 30 grid (total 900 nodes!) to the high dimensional data, then use the grid as a new lower-dimensional coordinate system against which to locate data.

```{r create_SOM}
# Define the grid system
som_grid <- somgrid(xdim=30, ydim=30, topo="hexagonal")

# Fit the model (remember, takes vectors or matrices!)
set.seed(7)
wine_som <- som(as.matrix(wine_df[,18:26]), grid=som_grid, rlen=100, alpha=c(0.05, 0.01))
```

The default plot the model can produce is pretty naff;

```{r visualise_SOM}
plot(wine_som)
```

Here I extract the coordinate data from the SOM to a new dataframe and add information on the highest probability topic and topic confidence ready for plotting my own!

```{r get_SOM_data}
# SOM Coordinates for greating my own prettier plot!
som_coords <- data.frame(wine_som$codes)
som_coords["x"] <- wine_som$grid$pts[,1]
som_coords["y"] <- wine_som$grid$pts[,2]

# Once again, assign by maximum probability
som_coords['topics'] <- colnames(som_coords)[apply(som_coords[,1:9], 1, max_index)]
som_coords['topic_conf'] <- apply(som_coords[,1:9], 1, max)

som_coords %>% arrange(topics) -> som_coords
```

### Test plot (editorial)

```{r test_plot_SOM_data}
# Create the base plot/colors
som_map <- ggplot(data=som_coords, aes(x=x, y=y, color=topics, fill=topics, size=topic_conf, alpha=topic_conf)) + 
  geom_point(pch=21) +
  scale_fill_brewer(palette="Set3") +
  scale_color_brewer(palette="Set3") +
  theme_minimal() +
  guides(alpha=FALSE)

som_map
```

### Get the Keyword Labels

Before we can plot the flavourmap, we need the labels for the centres of the 2D clusters, so we calculate the median points (more robust than mean to outliers, x and y medians calculated separately).  Then we import the top 10 keywords from the LDA model and join them ready for plotting.

```{r get_topic_word_dists}
# Finally, for each topic we need to find its x/y medioid (rather than mean, there are distant outliers)
som_coords %>% 
  group_by(topics) %>% 
  summarize(med_x = median(x), med_y = median(y)) -> som_medioids

# Add the keyword information to the medioids dataframe
colnames(word_dist_df)[3] <- "topics"
som_medioids %>% left_join(word_dist_df, by="topics") -> som_medioids
som_medioids['keywords'] <- paste(som_medioids$topics, som_medioids$keywords)
som_medioids
```

### Final Flavourmap/SOM plot

```{r plot_SOM_data}
# Create the base plot/colors
som_map <- ggplot(data=som_coords, aes(x=x, y=y, color=topics, fill=topics, size=topic_conf, alpha=topic_conf)) + 
  geom_point(pch=22) +
  scale_size_continuous(range = c(2, 12)) +
  labs(x="Sweet to Dry", y="Aged to Fruity", size="Topic Strength") +
  scale_fill_brewer(palette=vis_scheme) +
  scale_color_brewer(palette=vis_scheme) +
  geom_label(data=som_medioids, aes(x=med_x, y=med_y, alpha=1, label=stringr::str_wrap(keywords, 1)), inherit.aes=FALSE) +
  theme_minimal() + 
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  guides(alpha=FALSE)

som_map
ggsave("flavormap.png", width=12, height=7)
```

## Plot wine-topic profiles by country

```{r prep_topic_profiles}
# The first thing we need to do is reshape the dataframe to get the topics into long form
wine_df_long <- wine_df[,c("country", "description", "title", "X1", "X3", "X5", "X6", "X8", "X9", "X10", "X11", "X13")]
wine_df_long <- melt(wine_df_long, id=c("country", "description", "title"))

# Remove NA values
wine_df_long %>% drop_na() -> wine_df_long

# Create some better data for plotting this...
wine_df_long['counter'] <- 1.0
wine_df_long %>% group_by(country, variable) %>% summarize(num_entries = sum(counter), topic_prob = sum(value)) -> sum_tc

sum_tc <- sum_tc %>% filter(num_entries >= 1000) %>% arrange(variable)
sum_tc['topic_prob'] <- sum_tc['topic_prob'] / sum_tc['num_entries']

# Change vairable to character (forces intelligent ordering), reorder
sum_tc['topics'] <- as.character(sum_tc$variable)
sum_tc %>% arrange(topics)-> sum_tc
sum_tc
```

## Some exploratory test plots

```{r plot_profile_Chile}
# Note;  I should probably limit this later to countries with > 1000 wines!
subset <- wine_df_long[wine_df_long["country"]=="Chile",]
ggplot(subset, aes(x=variable, y=value)) + geom_col()
```

```{r plot_profile_France}
# Note;  I should probably limit this later to countries with > 1000 wines!
subset <- wine_df_long[wine_df_long["country"]=="France",]
ggplot(subset, aes(x=variable, y=value)) + geom_col()
```

## Final developed plot!

```{r plot_profiles_all}
# Note:  Need to fix the ordering!
ggplot(sum_tc, aes(x=topics, y=topic_prob, fill=topics)) + 
  scale_fill_brewer(palette=vis_scheme) + 
  labs(x="Topic", y="Topic Probability", fill = "Topics") +
  geom_col() + 
  coord_flip() + 
  facet_wrap(vars(country)) + 
  theme_minimal()

ggsave("country_topic_dist.png", width=12, height=7)
```

