{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an LDA model of wine descriptions,\n",
    "# how many are there \"really\"?\n",
    "\n",
    "Sure, there's 130,000 reviews of wines from around the world expounding their diverse tastes and characters, but how many \"really\" exist?  How many supergroups of wines that are essentially similar can be identified, and what's a representative example of each?  As someone who likes both red AND white wines (let's be honest; rose's just half and half) I feel uniquely qualified to answer this.  Let's perform a gid search of a large number of LDA models and find that with the best coherence & perplexity scores!  And then we'll visualise the countries of origin and the keywords that most characterise the qualities of these supergroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import re\n",
    "import random\n",
    "import pyLDAvis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "\n",
    "from gensim.models.ldamulticore import LdaModel\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import SnowballStemmer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "# Define which stemmer to use in the pipeline later\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv(\"./data/wine-reviews/winemag-data-130k-v2.csv\")\n",
    "wine_df['desc_len'] = wine_df['description'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Data exploration (I'm not doing much!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'country',\n",
       " 'description',\n",
       " 'designation',\n",
       " 'points',\n",
       " 'price',\n",
       " 'province',\n",
       " 'region_1',\n",
       " 'region_2',\n",
       " 'taster_name',\n",
       " 'taster_twitter_handle',\n",
       " 'title',\n",
       " 'variety',\n",
       " 'winery',\n",
       " 'desc_len']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>desc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>US</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>US</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>US</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   country  \\\n",
       "0  Aromas include tropical fruit, broom, brimston...     Italy   \n",
       "1  This is ripe and fruity, a wine that is smooth...  Portugal   \n",
       "2  Tart and snappy, the flavors of lime flesh and...        US   \n",
       "3  Pineapple rind, lemon pith and orange blossom ...        US   \n",
       "4  Much like the regular bottling from 2012, this...        US   \n",
       "\n",
       "          taster_name  desc_len  \n",
       "0       Kerin O’Keefe       172  \n",
       "1          Roger Voss       227  \n",
       "2        Paul Gregutt       186  \n",
       "3  Alexander Peartree       199  \n",
       "4        Paul Gregutt       249  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df[[\"description\", \"country\", \"taster_name\", \"desc_len\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick utility function to pre-process the text\n",
    "def preprocess_desc(description):\n",
    "    return( [stemmer.stem(token) for token in simple_preprocess(str(description)) if token not in STOPWORDS] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB;  This step could be improved through first filtering to words that are pronouns.\n",
    "wine_df['tokens'] = wine_df['description'].apply(preprocess_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>172</td>\n",
       "      <td>[aroma, includ, tropic, fruit, broom, brimston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>227</td>\n",
       "      <td>[ripe, fruiti, wine, smooth, structur, firm, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>US</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>186</td>\n",
       "      <td>[tart, snappi, flavor, lime, flesh, rind, domi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>US</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>199</td>\n",
       "      <td>[pineappl, rind, lemon, pith, orang, blossom, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>US</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>249</td>\n",
       "      <td>[like, regular, bottl, come, rough, tannic, ru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   country  \\\n",
       "0  Aromas include tropical fruit, broom, brimston...     Italy   \n",
       "1  This is ripe and fruity, a wine that is smooth...  Portugal   \n",
       "2  Tart and snappy, the flavors of lime flesh and...        US   \n",
       "3  Pineapple rind, lemon pith and orange blossom ...        US   \n",
       "4  Much like the regular bottling from 2012, this...        US   \n",
       "\n",
       "          taster_name  desc_len  \\\n",
       "0       Kerin O’Keefe       172   \n",
       "1          Roger Voss       227   \n",
       "2        Paul Gregutt       186   \n",
       "3  Alexander Peartree       199   \n",
       "4        Paul Gregutt       249   \n",
       "\n",
       "                                              tokens  \n",
       "0  [aroma, includ, tropic, fruit, broom, brimston...  \n",
       "1  [ripe, fruiti, wine, smooth, structur, firm, t...  \n",
       "2  [tart, snappi, flavor, lime, flesh, rind, domi...  \n",
       "3  [pineappl, rind, lemon, pith, orang, blossom, ...  \n",
       "4  [like, regular, bottl, come, rough, tannic, ru...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df[[\"description\", \"country\", \"taster_name\", \"desc_len\", \"tokens\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create TF-IDF representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocabulary record\n",
    "dictionary = gensim.corpora.Dictionary(wine_df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extreme values (words that are too rare, too common)\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BOW model\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in wine_df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From that create the TF-IDF model\n",
    "tfidf = gensim.models.TfidfModel(bow_corpus)\n",
    "wine_df['corpus_tfidf'] = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(0, 0.07160155708244689), (1, 0.1877195732633...\n",
       "1    [(0, 0.09083746481579533), (10, 0.063390218940...\n",
       "2    [(0, 0.07030752616398264), (33, 0.131602894540...\n",
       "3    [(3, 0.06051027977427229), (16, 0.064085312284...\n",
       "4    [(65, 0.129161659467362), (66, 0.2234435211947...\n",
       "Name: corpus_tfidf, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['corpus_tfidf'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Create LDA models (try a few!)\n",
    "Train-test split only, because I'm not iteratively improving anything here (it's for coursework dammit, no one cares!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(7)\n",
    "trainset, testset = train_test_split(wine_df, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tried 3 topics perplexity = -8.134159893306359 coherence = -2.0683865045577012\n",
      "tried 4 topics perplexity = -8.269554133873681 coherence = -2.0932255052976028\n",
      "tried 5 topics perplexity = -8.45754303160014 coherence = -2.146341883234046\n",
      "tried 6 topics perplexity = -8.621868042818727 coherence = -4.049721776884863\n",
      "tried 7 topics perplexity = -8.781977439839023 coherence = -2.1398669581777616\n",
      "tried 8 topics perplexity = -8.856188891809948 coherence = -7.743528954791789\n",
      "tried 9 topics perplexity = -9.016759790814767 coherence = -4.8888176384461985\n",
      "tried 10 topics perplexity = -9.17627224938949 coherence = -5.360438528111849\n",
      "tried 11 topics perplexity = -9.425007163344729 coherence = -5.035231079839597\n",
      "tried 12 topics perplexity = -9.725160330246982 coherence = -5.249061359865915\n",
      "tried 13 topics perplexity = -9.909611391295044 coherence = -10.670886791988334\n",
      "tried 14 topics perplexity = -10.102366778649392 coherence = -8.172530204728018\n",
      "tried 15 topics perplexity = -10.289885560148866 coherence = -7.208644765748473\n",
      "tried 16 topics perplexity = -10.407066241441182 coherence = -6.517426771919325\n",
      "tried 17 topics perplexity = -10.528655126902397 coherence = -7.411807650482453\n",
      "tried 18 topics perplexity = -10.649823036066884 coherence = -7.460578628021338\n",
      "tried 19 topics perplexity = -10.768096164740713 coherence = -8.95469960672008\n",
      "tried 20 topics perplexity = -10.90467098274927 coherence = -8.355104164885763\n",
      "tried 21 topics perplexity = -11.04004770270036 coherence = -8.490455057445276\n",
      "tried 22 topics perplexity = -11.14814725362634 coherence = -8.028826684745693\n",
      "tried 23 topics perplexity = -11.298303610366602 coherence = -8.18408191993139\n",
      "tried 24 topics perplexity = -11.389366547246532 coherence = -8.120578567626154\n",
      "tried 25 topics perplexity = -11.562511069829345 coherence = -8.034564989627679\n",
      "tried 26 topics perplexity = -11.67479371815767 coherence = -8.161491855675136\n",
      "tried 27 topics perplexity = -11.786690376420832 coherence = -9.403454263097178\n",
      "tried 28 topics perplexity = -11.866146972032174 coherence = -10.42575740844353\n",
      "tried 29 topics perplexity = -12.05207784904945 coherence = -8.538831304319258\n",
      "tried 30 topics perplexity = -12.125079864927088 coherence = -9.542633376323415\n",
      "tried 31 topics perplexity = -12.259949901827897 coherence = -9.686535573605623\n",
      "tried 32 topics perplexity = -12.384585684368805 coherence = -8.79367427713574\n",
      "tried 33 topics perplexity = -12.475166020977937 coherence = -9.673149716717809\n",
      "tried 34 topics perplexity = -12.60026314376418 coherence = -9.595798557373271\n",
      "tried 35 topics perplexity = -12.7408444153689 coherence = -10.769587973821869\n",
      "tried 36 topics perplexity = -12.806930897539642 coherence = -10.12652627047381\n",
      "tried 37 topics perplexity = -12.972536107303299 coherence = -9.840445091466927\n",
      "tried 38 topics perplexity = -13.0857982465871 coherence = -9.942040481167378\n",
      "tried 39 topics perplexity = -13.205889505901775 coherence = -10.377952869089594\n",
      "tried 40 topics perplexity = -13.308973562002373 coherence = -11.46249650227097\n",
      "tried 41 topics perplexity = -13.404838038979184 coherence = -10.298410718399202\n",
      "tried 42 topics perplexity = -13.60272330775742 coherence = -10.018630441805731\n",
      "tried 43 topics perplexity = -13.71541968926856 coherence = -10.076464129689219\n",
      "tried 44 topics perplexity = -13.813821926323184 coherence = -10.720150274532257\n",
      "tried 45 topics perplexity = -13.948540504282281 coherence = -11.762558946456368\n",
      "tried 46 topics perplexity = -14.120776646706483 coherence = -10.604349940293995\n",
      "tried 47 topics perplexity = -14.242878139379055 coherence = -11.175640033173908\n",
      "tried 48 topics perplexity = -14.45325691866399 coherence = -10.659799606890582\n",
      "tried 49 topics perplexity = -14.582484325455264 coherence = -11.076103997961397\n",
      "tried 50 topics perplexity = -14.801321444907364 coherence = -10.706020946445514\n"
     ]
    }
   ],
   "source": [
    "# Loop through a number of different topic model sizes\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for num_topics in range(3, 51):\n",
    "\n",
    "    # Fit the lda model, with 10 topics\n",
    "    lda_model_tfidf = LdaModel(trainset['corpus_tfidf'],\n",
    "                               num_topics=num_topics,\n",
    "                               id2word=dictionary,\n",
    "                               passes=2)\n",
    "    \n",
    "    # Get the perplexity\n",
    "    perplexity = lda_model_tfidf.log_perplexity(testset['corpus_tfidf'])\n",
    "    \n",
    "    # Get the coherence\n",
    "    cm = CoherenceModel(model=lda_model_tfidf, corpus=testset['corpus_tfidf'], coherence='u_mass')\n",
    "    coherence = cm.get_coherence()\n",
    "    \n",
    "    # record\n",
    "    results = results.append({\"topics\":num_topics, \"perplexity\":perplexity, \"coherence\":coherence}, ignore_index=True)\n",
    "    \n",
    "    # Report for my convenience\n",
    "    print(\"tried {} topics\".format(num_topics), \"perplexity = {}\".format(perplexity), \"coherence = {}\".format(coherence))\n",
    "\n",
    "results.to_csv(\"tested_lda_stats.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff80be65c88>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "sns.scatterplot(x=\"topics\", y=\"perplexity\", color=\"blue\", data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff820cc1668>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "sns.scatterplot(x=\"topics\", y=\"coherence\", color=\"red\", data=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Create the \"Best\" Model!\n",
    "\n",
    "So what's the \"best\" model according to my two somewhat-arbitrary metrics?  First off it's worth noting that the metrics follow a consistent downward trend.  We are looking for a low perplexity score and a high coherence score.  Our other constraint is that I, personally, don't believe there can be more than 15 \"true\" varieties of wines!\n",
    "\n",
    "This last constraint is both a cheat that undermines the entire idea, and absolutely neccessary.  Unless you've got a very weirdly well-divided, well fleshed-out dataset of fairly long documents there's not going to be a \"true\" underlying topic model.  There'll be overlap in topic, and worse the topics can be fractal in nature, sub-dividing and making it difficult to know where to call it quits.\n",
    "\n",
    "Within this constraint, models with 9, 10, 11 or 12 topics display a consistently good coherence score suggesting a some persistence in discovered topics.  Over this range we also see something of a step-change in perplexity, implying a qualitative improvement over having smaller numbers of topics.\n",
    "\n",
    "I choose 11 topics - the value comes on the down-side of that possible step-change in perplexity, and has a locally better coherence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the final lda model to all data\n",
    "lda_model_tfidf = LdaModel(wine_df['corpus_tfidf'],\n",
    "                           num_topics=11,\n",
    "                           id2word=dictionary,\n",
    "                           passes=2)\n",
    "\n",
    "# Get the perplexity, out of curiosity\n",
    "perplexity = lda_model_tfidf.log_perplexity(wine_df['corpus_tfidf'])\n",
    "    \n",
    "# Get the coherence, out of curiosity\n",
    "cm = CoherenceModel(model=lda_model_tfidf, corpus=wine_df['corpus_tfidf'], coherence='u_mass')\n",
    "coherence = cm.get_coherence()\n",
    "\n",
    "print(\"perplexity = {}\".format(perplexity), \"coherence = {}\".format(coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a quick look at the topics picked out\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how did we do?\n",
    "Well;  looking at the words involved there are some valid-looking clusters there with some very apparently citrusy wines separated from aged, oakey wines!  This is a success!  There's a sweet wine cluster too with cherries, blackberries, \"soft\" and \"sweet\" flavours mentioned.  There's also annoyingly a weird topic that may have more to do with ancilliary descriptions of how wines are constructed - topic 1, describing stainless steel apperatus, and words like \"vineyard\" and \"ferment\".\n",
    "\n",
    "An obvious solution;  Simply ignore that topic during processing/assignment to clusters/visualisation!  Topic 0 may also be ancilliary details, mentioning \"cover\", \"salmon\", \"rest\" and \"extra\" - words that imply a link to serving suggestions.\n",
    "\n",
    "This is ultimately a useful lesson in the divergence of the latent topics of the corpus (on wine TASTING) from the topics we were seeking (on wine FLAVOUR).  A really useful way to examine the fit of what we've created is to utilise pyLDAvis, which uses PCA to do exactly what it says on the tin!\n",
    "\n",
    "And as it happens it supports the earlier conclusion;  in the first two principal components (and ignoring the part where it mucked up the topic indexes) the topics related to fermentation and serving suggestions appear well separated from the topics related to flavour.  Additionally, topic 9 is out of the way too, it talks of \"nose\", \"gravel\", and then a list of herbs that frankly sound like they'd go well with beef.  This decision, that these three topics are not like the rest and not relevant to our aims, is bourne out by the proportion of the corpus assigned to them.  Each of the three rogue topics contains 2-5 % of documents (roughly eyeballed), whereas the \"valid\" topics contain closer to 10 % each typically.\n",
    "\n",
    "### Final Conclusion\n",
    "The best-fit (low topic number) model has 11 topics.  Of those, three topics (index 0, 1 and 9) appear to be invalid, representing aspects of the descriptions less relevant to flavour.  This leaves 8 \"valid\" topics to be presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-23327152e14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvis_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'corpus_tfidf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ozzy/.local/lib/python3.6/site-packages/pyLDAvis/gensim.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[1;32m    118\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ozzy/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[1;32m    396\u001b[0m    \u001b[0mterm_frequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m    \u001b[0mtopic_info\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0m_topic_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m    \u001b[0mtoken_table\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0m_token_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m    \u001b[0mtopic_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_topic_coordinates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_proportion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ozzy/.local/lib/python3.6/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m    top_terms = pd.concat(Parallel(n_jobs=n_jobs)(delayed(_find_relevance_chunks)(log_ttd, log_lift, R, ls) \\\n\u001b[0;32m--> 255\u001b[0;31m                                                  for ls in _job_chunks(lambda_seq, n_jobs)))\n\u001b[0m\u001b[1;32m    256\u001b[0m    \u001b[0mtopic_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_top_term_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_terms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdefault_term_info\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ozzy/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ozzy/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ozzy/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vis_data = gensimvis.prepare(lda_model_tfidf, wine_df['corpus_tfidf'], dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf.save(\"./models/lda_model_tfidf_11.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.  Save the results (and switch to R!)\n",
    "And for coursework reasons the visualisations of my brilliant work on wine must be presented using R.  I'll do some formatting and save the output topic models etc in some form R will like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = LdaModel.load(\"./models/lda_model_tfidf_11.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topics = [ [x[1] for x in doc] for doc in lda_model_tfidf.get_document_topics(wine_df['corpus_tfidf']) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.018757854,\n",
       "  0.018757995,\n",
       "  0.018759832,\n",
       "  0.018758893,\n",
       "  0.55141985,\n",
       "  0.1868327,\n",
       "  0.018759614,\n",
       "  0.01876138,\n",
       "  0.018761182,\n",
       "  0.1116721,\n",
       "  0.018758567],\n",
       " [0.020118373,\n",
       "  0.10271136,\n",
       "  0.02012037,\n",
       "  0.020118715,\n",
       "  0.02011846,\n",
       "  0.020118464,\n",
       "  0.02012011,\n",
       "  0.14763111,\n",
       "  0.020118715,\n",
       "  0.020117633,\n",
       "  0.58870673],\n",
       " [0.019674119,\n",
       "  0.35602343,\n",
       "  0.01967457,\n",
       "  0.46689016,\n",
       "  0.019680006,\n",
       "  0.019674566,\n",
       "  0.01967493,\n",
       "  0.019682227,\n",
       "  0.019675296,\n",
       "  0.019674884,\n",
       "  0.01967583],\n",
       " [0.3271295,\n",
       "  0.017177885,\n",
       "  0.01717926,\n",
       "  0.017182808,\n",
       "  0.5182525,\n",
       "  0.017178705,\n",
       "  0.017178932,\n",
       "  0.017179705,\n",
       "  0.017180199,\n",
       "  0.017180324,\n",
       "  0.01718022],\n",
       " [0.017358111,\n",
       "  0.017358176,\n",
       "  0.14325555,\n",
       "  0.017358864,\n",
       "  0.017359735,\n",
       "  0.084661685,\n",
       "  0.37818086,\n",
       "  0.2723894,\n",
       "  0.017359892,\n",
       "  0.017359335,\n",
       "  0.01735843]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_df = pd.DataFrame(doc_topics)\n",
    "doc_topic_df['title'] = wine_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.018758</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.551420</td>\n",
       "      <td>0.186833</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.111672</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.102711</td>\n",
       "      <td>0.020120</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.020120</td>\n",
       "      <td>0.147631</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.588707</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019674</td>\n",
       "      <td>0.356023</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.466890</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.019682</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.019676</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.327130</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.017183</td>\n",
       "      <td>0.518252</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.143256</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.084662</td>\n",
       "      <td>0.378181</td>\n",
       "      <td>0.272389</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.018758  0.018758  0.018760  0.018759  0.551420  0.186833  0.018760   \n",
       "1  0.020118  0.102711  0.020120  0.020119  0.020118  0.020118  0.020120   \n",
       "2  0.019674  0.356023  0.019675  0.466890  0.019680  0.019675  0.019675   \n",
       "3  0.327130  0.017178  0.017179  0.017183  0.518252  0.017179  0.017179   \n",
       "4  0.017358  0.017358  0.143256  0.017359  0.017360  0.084662  0.378181   \n",
       "\n",
       "          7         8         9        10  \\\n",
       "0  0.018761  0.018761  0.111672  0.018759   \n",
       "1  0.147631  0.020119  0.020118  0.588707   \n",
       "2  0.019682  0.019675  0.019675  0.019676   \n",
       "3  0.017180  0.017180  0.017180  0.017180   \n",
       "4  0.272389  0.017360  0.017359  0.017358   \n",
       "\n",
       "                                               title  \n",
       "0                  Nicosia 2013 Vulkà Bianco  (Etna)  \n",
       "1      Quinta dos Avidagos 2011 Avidagos Red (Douro)  \n",
       "2      Rainstorm 2013 Pinot Gris (Willamette Valley)  \n",
       "3  St. Julian 2013 Reserve Late Harvest Riesling ...  \n",
       "4  Sweet Cheeks 2012 Vintner's Reserve Wild Child...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wine_df.merge(doc_topic_df, on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>[aroma, includ, tropic, fruit, broom, brimston...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>[ripe, fruiti, wine, smooth, structur, firm, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>[tart, snappi, flavor, lime, flesh, rind, domi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>[pineappl, rind, lemon, pith, orang, blossom, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>[like, regular, bottl, come, rough, tannic, ru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Aromas include tropical fruit, broom, brimston...   \n",
       "1  This is ripe and fruity, a wine that is smooth...   \n",
       "2  Tart and snappy, the flavors of lime flesh and...   \n",
       "3  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [aroma, includ, tropic, fruit, broom, brimston...  \n",
       "1  [ripe, fruiti, wine, smooth, structur, firm, t...  \n",
       "2  [tart, snappi, flavor, lime, flesh, rind, domi...  \n",
       "3  [pineappl, rind, lemon, pith, orang, blossom, ...  \n",
       "4  [like, regular, bottl, come, rough, tannic, ru...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['description', 'tokens']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"wine_reviews_with_topic_distributions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
